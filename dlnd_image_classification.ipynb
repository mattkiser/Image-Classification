{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 4:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1003, 1: 963, 2: 1041, 3: 976, 4: 1004, 5: 1021, 6: 1004, 7: 981, 8: 1024, 9: 983}\n",
      "First 20 Labels: [0, 6, 0, 2, 7, 2, 1, 2, 4, 1, 5, 6, 6, 3, 1, 3, 5, 5, 8, 1]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 13 Max Value: 169\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 2 Name: bird\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBD0ANCboAaAxQQ8AjQl6AGjs/wC42Lcq2cSEgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f99658c8710>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 4\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    a = 0.0\n",
    "    b = 1.0\n",
    "    x_minval = np.min(x)\n",
    "    x_maxval = np.max(x)\n",
    "    return a + ( ( (x - x_minval)*(b - a) )/(x_maxval - x_minval) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = None\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    global lb\n",
    "    if lb is None:\n",
    "        lb = preprocessing.LabelBinarizer()\n",
    "        lb.fit(x)\n",
    "    oneHot = lb.transform(x)\n",
    "    return oneHot\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None,*image_shape], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=(None,n_classes), name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    return keep_prob\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.truncated_normal([*conv_ksize, int(x_tensor.shape[3]), conv_num_outputs],\n",
    "                                             mean=0.0,     # EDIT THIS\n",
    "                                             stddev=0.03,  # EDIT THIS\n",
    "                                             dtype=tf.float32))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    conv_layer = tf.nn.conv2d(input=x_tensor, \n",
    "                              filter=weight, \n",
    "                              strides=[1,*conv_strides,1], \n",
    "                              padding='SAME')\n",
    "    \n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    \n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    conv_layer = tf.nn.max_pool(value=conv_layer, \n",
    "                                ksize = [1, *pool_ksize,1],\n",
    "                                strides = [1, *pool_strides, 1], \n",
    "                                padding='SAME')\n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    flattened_tensor = tf.contrib.layers.flatten(x_tensor)\n",
    "    return flattened_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    output = tf.contrib.layers.fully_connected(x_tensor, \n",
    "                                               num_outputs,\n",
    "                                               )\n",
    "    return output\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    output = tf.contrib.layers.fully_connected(x_tensor, \n",
    "                                               num_outputs,\n",
    "                                               activation_fn = None)\n",
    "    return output\n",
    "\n",
    "#the same as the fully connected layer?\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    conv_num_outputs1 = 16              #         EDIT HERE\n",
    "    conv_num_outputs2 = 32              #         EDIT HERE\n",
    "    conv_num_outputs3 = 64              #         EDIT HERE\n",
    "    \n",
    "    conv_ksize1 = (4,4)              #         EDIT HERE\n",
    "    conv_ksize2 = (4,4)              #         EDIT HERE\n",
    "    conv_ksize3 = (4,4)              #         EDIT HERE\n",
    "    \n",
    "    conv_strides1 = (2,2)              #         EDIT HERE\n",
    "    conv_strides2 = (2,2)              #         EDIT HERE\n",
    "    conv_strides3 = (2,2)              #         EDIT HERE\n",
    "    \n",
    "    pool_ksize1 = (2,2)              #         EDIT HERE\n",
    "    pool_ksize2 = (2,2)              #         EDIT HERE\n",
    "    pool_ksize3 = (1,1)              #         EDIT HERE\n",
    "    \n",
    "    pool_strides1 = (1,1)              #         EDIT HERE\n",
    "    pool_strides2 = (2,2)              #         EDIT HERE\n",
    "    pool_strides3 = (1,1)              #         EDIT HERE\n",
    "    \n",
    "    conv1 = conv2d_maxpool(x,\n",
    "                           conv_num_outputs=conv_num_outputs1,\n",
    "                           conv_ksize=conv_ksize1,\n",
    "                           conv_strides=conv_strides1,\n",
    "                           pool_ksize=pool_ksize1,\n",
    "                           pool_strides=pool_strides1)\n",
    "    conv2 = conv2d_maxpool(conv1,\n",
    "                           conv_num_outputs=conv_num_outputs2,\n",
    "                           conv_ksize=conv_ksize2,\n",
    "                           conv_strides=conv_strides2,\n",
    "                           pool_ksize=pool_ksize2,\n",
    "                           pool_strides=pool_strides2)\n",
    "    conv3 = conv2d_maxpool(conv2,\n",
    "                           conv_num_outputs=conv_num_outputs3,\n",
    "                           conv_ksize=conv_ksize3,\n",
    "                           conv_strides=conv_strides3,\n",
    "                           pool_ksize=pool_ksize3,\n",
    "                           pool_strides=pool_strides3)\n",
    "    conv3 = tf.nn.dropout(conv3, keep_prob)\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    \n",
    "    flat_layer = flatten(conv3)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    \n",
    "    fully_co = fully_conn(flat_layer,1500)           #          EDIT HERE\n",
    "    fully_co = tf.nn.dropout(fully_co, keep_prob)\n",
    "    fully_co = fully_conn(fully_co,750)              #         EDIT HERE\n",
    "    fully_co = tf.nn.dropout(fully_co, keep_prob)\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    out = output(fully_co, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, \n",
    "                feed_dict={x:feature_batch, \n",
    "                           y:label_batch, \n",
    "                           keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = sess.run(cost, feed_dict={x: feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    accuracy = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels,keep_prob: 1.0})\n",
    "    print('Loss at {}'.format(loss), 'Validation Accuracy at {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss at 2.206547737121582 Validation Accuracy at 0.20299997925758362\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss at 2.0916175842285156 Validation Accuracy at 0.3115999698638916\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss at 1.965047836303711 Validation Accuracy at 0.35439997911453247\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss at 1.844254732131958 Validation Accuracy at 0.38960000872612\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss at 1.708388090133667 Validation Accuracy at 0.40779995918273926\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss at 1.5947937965393066 Validation Accuracy at 0.4145999550819397\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss at 1.4773380756378174 Validation Accuracy at 0.43139997124671936\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss at 1.413043737411499 Validation Accuracy at 0.4559999704360962\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss at 1.325329065322876 Validation Accuracy at 0.46459993720054626\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss at 1.1907464265823364 Validation Accuracy at 0.47819995880126953\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss at 1.122756004333496 Validation Accuracy at 0.486799955368042\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss at 1.076647400856018 Validation Accuracy at 0.47919994592666626\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss at 0.9383043050765991 Validation Accuracy at 0.5055999159812927\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss at 0.9259020686149597 Validation Accuracy at 0.5133998990058899\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss at 0.8344804048538208 Validation Accuracy at 0.5209999680519104\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss at 0.7965421676635742 Validation Accuracy at 0.5223999619483948\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss at 0.7278392314910889 Validation Accuracy at 0.5199999809265137\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss at 0.6991660594940186 Validation Accuracy at 0.5231999158859253\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss at 0.6691974401473999 Validation Accuracy at 0.525399923324585\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss at 0.6228132843971252 Validation Accuracy at 0.530799925327301\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss at 0.5773054361343384 Validation Accuracy at 0.5353999137878418\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss at 0.5426777005195618 Validation Accuracy at 0.533799946308136\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss at 0.524054765701294 Validation Accuracy at 0.5445999503135681\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss at 0.5030349493026733 Validation Accuracy at 0.5387999415397644\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss at 0.4618563950061798 Validation Accuracy at 0.5343999266624451\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss at 0.4057297706604004 Validation Accuracy at 0.5553998947143555\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss at 0.40851083397865295 Validation Accuracy at 0.5411999821662903\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss at 0.3812501132488251 Validation Accuracy at 0.5405999422073364\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss at 0.34664028882980347 Validation Accuracy at 0.5527998805046082\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss at 0.31668683886528015 Validation Accuracy at 0.5595999360084534\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss at 0.2901133894920349 Validation Accuracy at 0.5587999224662781\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss at 0.2898014187812805 Validation Accuracy at 0.5643998980522156\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss at 0.2775387763977051 Validation Accuracy at 0.5507999062538147\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss at 0.2653142809867859 Validation Accuracy at 0.5453999638557434\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss at 0.30760788917541504 Validation Accuracy at 0.5475999712944031\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss at 0.2642599940299988 Validation Accuracy at 0.5717999935150146\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss at 0.25452283024787903 Validation Accuracy at 0.5639999508857727\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss at 0.23979595303535461 Validation Accuracy at 0.5607999563217163\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss at 0.19940929114818573 Validation Accuracy at 0.5655999183654785\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss at 0.2222180813550949 Validation Accuracy at 0.5461999773979187\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss at 0.20427648723125458 Validation Accuracy at 0.5497999787330627\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss at 0.21544885635375977 Validation Accuracy at 0.5397999286651611\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss at 0.20458129048347473 Validation Accuracy at 0.5417999029159546\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss at 0.1756007969379425 Validation Accuracy at 0.5567999482154846\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss at 0.1486375331878662 Validation Accuracy at 0.5553998947143555\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss at 0.20607034862041473 Validation Accuracy at 0.5311999917030334\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss at 0.16823835670948029 Validation Accuracy at 0.5567999482154846\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss at 0.17278516292572021 Validation Accuracy at 0.5483999252319336\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss at 0.13843794167041779 Validation Accuracy at 0.5645999312400818\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss at 0.1387239396572113 Validation Accuracy at 0.5583999156951904\n"
     ]
    }
   ],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "keep_probability = .5\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss at 2.193650722503662 Validation Accuracy at 0.2223999947309494\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss at 1.984224557876587 Validation Accuracy at 0.295199990272522\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss at 1.6377768516540527 Validation Accuracy at 0.3392000198364258\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss at 1.6786500215530396 Validation Accuracy at 0.38979995250701904\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss at 1.6508862972259521 Validation Accuracy at 0.4103999733924866\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss at 1.815701961517334 Validation Accuracy at 0.4323999583721161\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss at 1.7091511487960815 Validation Accuracy at 0.43699997663497925\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss at 1.295881748199463 Validation Accuracy at 0.44259998202323914\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss at 1.469321846961975 Validation Accuracy at 0.46699994802474976\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss at 1.5291131734848022 Validation Accuracy at 0.464199960231781\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss at 1.4978994131088257 Validation Accuracy at 0.47519996762275696\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss at 1.4570255279541016 Validation Accuracy at 0.4771999716758728\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss at 1.126615285873413 Validation Accuracy at 0.48899996280670166\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss at 1.2933177947998047 Validation Accuracy at 0.5069999694824219\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss at 1.4052176475524902 Validation Accuracy at 0.49839991331100464\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss at 1.33164644241333 Validation Accuracy at 0.5123999118804932\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss at 1.3106739521026611 Validation Accuracy at 0.47659993171691895\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss at 0.9674947261810303 Validation Accuracy at 0.4851999878883362\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss at 1.1798593997955322 Validation Accuracy at 0.5163999199867249\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss at 1.302161693572998 Validation Accuracy at 0.514799952507019\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss at 1.2870824337005615 Validation Accuracy at 0.5309999585151672\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss at 1.1812063455581665 Validation Accuracy at 0.5237999558448792\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss at 0.9029313325881958 Validation Accuracy at 0.5255999565124512\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss at 1.056104063987732 Validation Accuracy at 0.5419999361038208\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss at 1.1558451652526855 Validation Accuracy at 0.5397999882698059\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss at 1.1517846584320068 Validation Accuracy at 0.5523999333381653\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss at 1.0828509330749512 Validation Accuracy at 0.5521999597549438\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss at 0.8141902089118958 Validation Accuracy at 0.5441999435424805\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss at 0.8702197074890137 Validation Accuracy at 0.5697999000549316\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss at 1.0748567581176758 Validation Accuracy at 0.5435999035835266\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss at 1.0322771072387695 Validation Accuracy at 0.5695999264717102\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss at 0.9992212057113647 Validation Accuracy at 0.572399914264679\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss at 0.7549936771392822 Validation Accuracy at 0.5791999101638794\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss at 0.8319191932678223 Validation Accuracy at 0.5735999345779419\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss at 0.9476118683815002 Validation Accuracy at 0.5715999007225037\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss at 0.9397004842758179 Validation Accuracy at 0.5895999073982239\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss at 0.9538183212280273 Validation Accuracy at 0.5835999250411987\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss at 0.7505329251289368 Validation Accuracy at 0.5793998837471008\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss at 0.7647067904472351 Validation Accuracy at 0.593999981880188\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss at 0.887069046497345 Validation Accuracy at 0.5921999216079712\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss at 0.8037420511245728 Validation Accuracy at 0.5977998971939087\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss at 0.8852840662002563 Validation Accuracy at 0.6037999391555786\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss at 0.6645662188529968 Validation Accuracy at 0.5901999473571777\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss at 0.7066764831542969 Validation Accuracy at 0.6029999256134033\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss at 0.8119498491287231 Validation Accuracy at 0.6019999384880066\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss at 0.8051537871360779 Validation Accuracy at 0.6005998849868774\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss at 0.8099277019500732 Validation Accuracy at 0.5947999954223633\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss at 0.5907160043716431 Validation Accuracy at 0.6011999249458313\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss at 0.6959311962127686 Validation Accuracy at 0.6083998680114746\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss at 0.7426322102546692 Validation Accuracy at 0.6061999201774597\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss at 0.6974421739578247 Validation Accuracy at 0.6189998984336853\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss at 0.7836315631866455 Validation Accuracy at 0.605199933052063\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss at 0.5914047360420227 Validation Accuracy at 0.6079999208450317\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss at 0.6838469505310059 Validation Accuracy at 0.6181999444961548\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss at 0.7318906784057617 Validation Accuracy at 0.6093999147415161\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss at 0.7194604873657227 Validation Accuracy at 0.6273999214172363\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss at 0.7356204986572266 Validation Accuracy at 0.6279999017715454\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss at 0.5511863231658936 Validation Accuracy at 0.6297998428344727\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss at 0.6466369032859802 Validation Accuracy at 0.6305999159812927\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss at 0.6743798851966858 Validation Accuracy at 0.6123999357223511\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss at 0.630968451499939 Validation Accuracy at 0.6283999085426331\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss at 0.7517865896224976 Validation Accuracy at 0.61819988489151\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss at 0.5312407612800598 Validation Accuracy at 0.6271999478340149\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss at 0.6348128318786621 Validation Accuracy at 0.6321998834609985\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss at 0.5934047698974609 Validation Accuracy at 0.6379998922348022\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss at 0.6336340308189392 Validation Accuracy at 0.6169999241828918\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss at 0.6771050095558167 Validation Accuracy at 0.6265998482704163\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss at 0.5508058071136475 Validation Accuracy at 0.6267999410629272\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss at 0.650671660900116 Validation Accuracy at 0.6291999220848083\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss at 0.5611790418624878 Validation Accuracy at 0.6203998923301697\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss at 0.5970979332923889 Validation Accuracy at 0.643799901008606\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss at 0.6350371837615967 Validation Accuracy at 0.6303998827934265\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss at 0.48413610458374023 Validation Accuracy at 0.6403998732566833\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss at 0.5532529354095459 Validation Accuracy at 0.643799901008606\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss at 0.5309745073318481 Validation Accuracy at 0.6381999254226685\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss at 0.5542895793914795 Validation Accuracy at 0.6501998901367188\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss at 0.5688661932945251 Validation Accuracy at 0.6501998901367188\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss at 0.4904521703720093 Validation Accuracy at 0.6379998326301575\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss at 0.5710785388946533 Validation Accuracy at 0.6475998759269714\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss at 0.5562219619750977 Validation Accuracy at 0.6315999627113342\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss at 0.5819661617279053 Validation Accuracy at 0.6453998684883118\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss at 0.5786128044128418 Validation Accuracy at 0.6379998922348022\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss at 0.4704435169696808 Validation Accuracy at 0.6457998752593994\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss at 0.5435000658035278 Validation Accuracy at 0.6441999077796936\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss at 0.480563223361969 Validation Accuracy at 0.6457999348640442\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss at 0.5317075848579407 Validation Accuracy at 0.6457998752593994\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss at 0.5277544260025024 Validation Accuracy at 0.6497998833656311\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss at 0.3907521963119507 Validation Accuracy at 0.6495998501777649\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss at 0.5369383692741394 Validation Accuracy at 0.6521998643875122\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss at 0.4882931411266327 Validation Accuracy at 0.6371999382972717\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss at 0.5124928951263428 Validation Accuracy at 0.6623998880386353\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss at 0.5508694648742676 Validation Accuracy at 0.6483998894691467\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss at 0.39555278420448303 Validation Accuracy at 0.6563999056816101\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss at 0.5102108716964722 Validation Accuracy at 0.6649998426437378\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss at 0.4683857858181 Validation Accuracy at 0.6235998868942261\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss at 0.5330630540847778 Validation Accuracy at 0.6563998460769653\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss at 0.5540807247161865 Validation Accuracy at 0.6367998719215393\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss at 0.3938077986240387 Validation Accuracy at 0.6545999050140381\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss at 0.46776294708251953 Validation Accuracy at 0.6581999063491821\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss at 0.47866570949554443 Validation Accuracy at 0.6345999240875244\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss at 0.4779026210308075 Validation Accuracy at 0.6569998860359192\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss at 0.4768966734409332 Validation Accuracy at 0.6537998914718628\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss at 0.37091538310050964 Validation Accuracy at 0.6433998942375183\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss at 0.42574000358581543 Validation Accuracy at 0.6701998710632324\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss at 0.4079098105430603 Validation Accuracy at 0.6529999375343323\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss at 0.4835796356201172 Validation Accuracy at 0.6567999124526978\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss at 0.5010462999343872 Validation Accuracy at 0.6403999328613281\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss at 0.3472951352596283 Validation Accuracy at 0.6663998961448669\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss at 0.44132766127586365 Validation Accuracy at 0.6675999164581299\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss at 0.4160304665565491 Validation Accuracy at 0.6539998650550842\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss at 0.4474197030067444 Validation Accuracy at 0.660399854183197\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss at 0.44273266196250916 Validation Accuracy at 0.6649998426437378\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss at 0.34357547760009766 Validation Accuracy at 0.6577998995780945\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss at 0.4440245032310486 Validation Accuracy at 0.6693998575210571\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss at 0.4174036383628845 Validation Accuracy at 0.6457999348640442\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss at 0.48817628622055054 Validation Accuracy at 0.6703998446464539\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss at 0.4391440153121948 Validation Accuracy at 0.6673998832702637\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss at 0.3261915445327759 Validation Accuracy at 0.6637998819351196\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss at 0.4201771020889282 Validation Accuracy at 0.6725997924804688\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss at 0.42705628275871277 Validation Accuracy at 0.6457998752593994\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss at 0.43356645107269287 Validation Accuracy at 0.6647998690605164\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss at 0.4171667993068695 Validation Accuracy at 0.673399806022644\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss at 0.301186203956604 Validation Accuracy at 0.6667998433113098\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss at 0.4114062190055847 Validation Accuracy at 0.676399827003479\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss at 0.3850162625312805 Validation Accuracy at 0.6563998460769653\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss at 0.41141608357429504 Validation Accuracy at 0.6723998785018921\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss at 0.4111340045928955 Validation Accuracy at 0.6689999103546143\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss at 0.2868746519088745 Validation Accuracy at 0.6675998568534851\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss at 0.3800026774406433 Validation Accuracy at 0.6751998662948608\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss at 0.35755252838134766 Validation Accuracy at 0.66159987449646\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss at 0.4034859538078308 Validation Accuracy at 0.6739999055862427\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss at 0.435198575258255 Validation Accuracy at 0.6713998317718506\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss at 0.2881423234939575 Validation Accuracy at 0.6739999055862427\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss at 0.3772887885570526 Validation Accuracy at 0.6801998615264893\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss at 0.3634311258792877 Validation Accuracy at 0.6551998853683472\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss at 0.4026356339454651 Validation Accuracy at 0.6751998662948608\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss at 0.4389054477214813 Validation Accuracy at 0.6819998621940613\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss at 0.28945720195770264 Validation Accuracy at 0.6691998243331909\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss at 0.35611772537231445 Validation Accuracy at 0.6781998872756958\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss at 0.3497735857963562 Validation Accuracy at 0.6551998853683472\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss at 0.3934544324874878 Validation Accuracy at 0.6675999164581299\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss at 0.42554962635040283 Validation Accuracy at 0.6707999110221863\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss at 0.2732059359550476 Validation Accuracy at 0.6709998250007629\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss at 0.33349570631980896 Validation Accuracy at 0.6845998167991638\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss at 0.3594614863395691 Validation Accuracy at 0.6747998595237732\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss at 0.45435938239097595 Validation Accuracy at 0.6635999083518982\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss at 0.35756587982177734 Validation Accuracy at 0.6825998425483704\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss at 0.2734876275062561 Validation Accuracy at 0.6757998466491699\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss at 0.3340452313423157 Validation Accuracy at 0.6825999021530151\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss at 0.33837205171585083 Validation Accuracy at 0.6737998127937317\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss at 0.3794170618057251 Validation Accuracy at 0.6677998304367065\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss at 0.35378241539001465 Validation Accuracy at 0.6811999082565308\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss at 0.2505732476711273 Validation Accuracy at 0.6867998242378235\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss at 0.3118124306201935 Validation Accuracy at 0.6849998831748962\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss at 0.33925455808639526 Validation Accuracy at 0.66159987449646\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss at 0.3846311569213867 Validation Accuracy at 0.6581999063491821\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss at 0.3812103867530823 Validation Accuracy at 0.6865999102592468\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss at 0.2760652005672455 Validation Accuracy at 0.6611999273300171\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss at 0.3098162114620209 Validation Accuracy at 0.6911998987197876\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss at 0.3177594542503357 Validation Accuracy at 0.681399941444397\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss at 0.32749369740486145 Validation Accuracy at 0.681399941444397\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss at 0.35586825013160706 Validation Accuracy at 0.6733998656272888\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss at 0.23417995870113373 Validation Accuracy at 0.6825999021530151\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss at 0.31702783703804016 Validation Accuracy at 0.6831998825073242\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss at 0.3264531195163727 Validation Accuracy at 0.6881999373435974\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss at 0.3456155061721802 Validation Accuracy at 0.6749998927116394\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss at 0.2997356951236725 Validation Accuracy at 0.6849998831748962\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss at 0.22177493572235107 Validation Accuracy at 0.6847999095916748\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss at 0.30288368463516235 Validation Accuracy at 0.6807999014854431\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss at 0.317137748003006 Validation Accuracy at 0.6683998703956604\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss at 0.30208829045295715 Validation Accuracy at 0.6773998141288757\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss at 0.3069903254508972 Validation Accuracy at 0.675399899482727\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss at 0.21304214000701904 Validation Accuracy at 0.6859999299049377\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss at 0.32140013575553894 Validation Accuracy at 0.6769999265670776\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss at 0.30439743399620056 Validation Accuracy at 0.6821999549865723\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss at 0.28038620948791504 Validation Accuracy at 0.6803998947143555\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss at 0.34574607014656067 Validation Accuracy at 0.6837998032569885\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss at 0.21325808763504028 Validation Accuracy at 0.683199942111969\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss at 0.282972514629364 Validation Accuracy at 0.6825998425483704\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss at 0.32382309436798096 Validation Accuracy at 0.6683998107910156\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss at 0.3103397786617279 Validation Accuracy at 0.6711999177932739\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss at 0.2966621518135071 Validation Accuracy at 0.6843998432159424\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss at 0.1885392963886261 Validation Accuracy at 0.6837998032569885\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss at 0.30755722522735596 Validation Accuracy at 0.6771999001502991\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss at 0.3015986680984497 Validation Accuracy at 0.672999918460846\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss at 0.30981773138046265 Validation Accuracy at 0.6717998385429382\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss at 0.29180553555488586 Validation Accuracy at 0.6805998682975769\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss at 0.2170226275920868 Validation Accuracy at 0.6811999082565308\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss at 0.27215439081192017 Validation Accuracy at 0.6839998960494995\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss at 0.282817006111145 Validation Accuracy at 0.6705998778343201\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss at 0.3340882360935211 Validation Accuracy at 0.654999852180481\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss at 0.27396246790885925 Validation Accuracy at 0.685999870300293\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss at 0.20881898701190948 Validation Accuracy at 0.6809998154640198\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss at 0.24254083633422852 Validation Accuracy at 0.686599850654602\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss at 0.2795025110244751 Validation Accuracy at 0.6867998838424683\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss at 0.27671465277671814 Validation Accuracy at 0.6887998580932617\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss at 0.28843191266059875 Validation Accuracy at 0.6923998594284058\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss at 0.1876738965511322 Validation Accuracy at 0.6935998797416687\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss at 0.23037675023078918 Validation Accuracy at 0.6903998255729675\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss at 0.2650854289531708 Validation Accuracy at 0.6795998811721802\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss at 0.2738959789276123 Validation Accuracy at 0.6863998770713806\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss at 0.2706946134567261 Validation Accuracy at 0.6765998601913452\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss at 0.18867748975753784 Validation Accuracy at 0.6891998052597046\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss at 0.27671027183532715 Validation Accuracy at 0.6851998567581177\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss at 0.243892639875412 Validation Accuracy at 0.6833998560905457\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss at 0.2661544382572174 Validation Accuracy at 0.682999849319458\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss at 0.2738781273365021 Validation Accuracy at 0.6945998668670654\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss at 0.2256426364183426 Validation Accuracy at 0.6769998669624329\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss at 0.26269543170928955 Validation Accuracy at 0.6941999197006226\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss at 0.2662520408630371 Validation Accuracy at 0.6791998147964478\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss at 0.2873328924179077 Validation Accuracy at 0.6751998066902161\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss at 0.2620188295841217 Validation Accuracy at 0.6789999008178711\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss at 0.19359920918941498 Validation Accuracy at 0.67659991979599\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss at 0.2503131926059723 Validation Accuracy at 0.6873998641967773\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss at 0.24342863261699677 Validation Accuracy at 0.6835998892784119\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss at 0.25392594933509827 Validation Accuracy at 0.6839998364448547\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss at 0.26650506258010864 Validation Accuracy at 0.6903998255729675\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss at 0.18934868276119232 Validation Accuracy at 0.6839998364448547\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss at 0.2277485430240631 Validation Accuracy at 0.6935998797416687\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss at 0.2327711433172226 Validation Accuracy at 0.6917998790740967\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss at 0.23316951096057892 Validation Accuracy at 0.6833998560905457\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss at 0.2538699507713318 Validation Accuracy at 0.691399872303009\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss at 0.1850626915693283 Validation Accuracy at 0.6831998229026794\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss at 0.23832666873931885 Validation Accuracy at 0.6907998919487\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss at 0.22407789528369904 Validation Accuracy at 0.6903998255729675\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss at 0.241133451461792 Validation Accuracy at 0.6905998587608337\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss at 0.2450401484966278 Validation Accuracy at 0.6931998133659363\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss at 0.18132847547531128 Validation Accuracy at 0.6917998194694519\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss at 0.2155175358057022 Validation Accuracy at 0.6935999393463135\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss at 0.2294984757900238 Validation Accuracy at 0.6953998804092407\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss at 0.22553540766239166 Validation Accuracy at 0.692599892616272\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss at 0.2317308485507965 Validation Accuracy at 0.6937998533248901\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss at 0.18610221147537231 Validation Accuracy at 0.6951999068260193\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss at 0.22252821922302246 Validation Accuracy at 0.6951999068260193\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss at 0.24268071353435516 Validation Accuracy at 0.6915998458862305\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss at 0.227633535861969 Validation Accuracy at 0.6861998438835144\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss at 0.23434478044509888 Validation Accuracy at 0.6957998275756836\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss at 0.15863582491874695 Validation Accuracy at 0.6909998655319214\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss at 0.19418366253376007 Validation Accuracy at 0.6967998743057251\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss at 0.24036552011966705 Validation Accuracy at 0.6885998249053955\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss at 0.23020502924919128 Validation Accuracy at 0.6965998411178589\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss at 0.2048431634902954 Validation Accuracy at 0.700999915599823\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss at 0.14774349331855774 Validation Accuracy at 0.6991998553276062\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss at 0.2278503179550171 Validation Accuracy at 0.6837998628616333\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss at 0.1995825320482254 Validation Accuracy at 0.689599871635437\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss at 0.2323855757713318 Validation Accuracy at 0.6879999041557312\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss at 0.22782984375953674 Validation Accuracy at 0.6989998817443848\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss at 0.15490128099918365 Validation Accuracy at 0.6929998397827148\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss at 0.2056034803390503 Validation Accuracy at 0.6959998607635498\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss at 0.21918536722660065 Validation Accuracy at 0.6909999251365662\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6876953125\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiEv1/TJE2HPXFVFkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa1ec357ef0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
